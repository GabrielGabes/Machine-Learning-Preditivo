{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd254111",
   "metadata": {},
   "source": [
    "# Book 4 - Modelo XGBoost\n",
    "\n",
    "Este notebook serviu como registro prático e teórico no meu aprendizado de Machine Learning.\n",
    "\n",
    "`Enriqueci este notebook com anotações adicionais e aplicações práticas tornando-o uma referência valiosa para consultas e implementações em futuros projetos reais.`\n",
    "\n",
    "Espero que este material inspire outros a explorar ainda mais o fascinante mundo do Machine Learning. \n",
    "\n",
    "Este notebook é centrado no modelo XGBoost, que é baseado nas árvores de decisão. Ele combina o resultado de várias árvores para formar um comitê de decisão robusto, que vem ganhando popularidade e favoritismo nas competições de machine learning devido seu ótimo desempenho.\n",
    "\n",
    "Tópicos abordados na aplicação do XGBoost:\n",
    "\n",
    "- **Validação Cruzada**\n",
    "- **Ajuste Hiperparâmetros**\n",
    "- **Boosting**\n",
    "- **Stacking**\n",
    "\n",
    "\n",
    "Compartilhar conhecimento é uma alegria—viva ao aprendizado contínuo, boa pratica e bons estudo a quem estiver lendo, abraços!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f61e6d",
   "metadata": {},
   "source": [
    "# Funções, bibliotecas e Dataframe ficticios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1fe453",
   "metadata": {},
   "outputs": [],
   "source": [
    "grandom_state = 3141592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3242ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "# Manipulação e Tratamento de dados\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import NaN\n",
    "\n",
    "#ignorando Warning inuteis\n",
    "import warnings \n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb277f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/fake_database.py\n",
      "https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/funcoes_estatisticas.py\n",
      "https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/ML_supervised_learning.py\n",
      "TUDO OK\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# CARREGANDO BASE\n",
    "arquivo = 'fake_database'\n",
    "url = \"https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/\" + arquivo + \".py\"\n",
    "print(url)\n",
    "#response = requests.get(url); code = response.text; exec(code)\n",
    "#df = fake_database2(2250); df_bck = df.copy(); display(df.head())\n",
    "\n",
    "arquivo = 'funcoes_estatisticas'\n",
    "url = \"https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/\" + arquivo + \".py\"\n",
    "print(url)\n",
    "response = requests.get(url); code = response.text; exec(code)\n",
    "\n",
    "# Função para avaliação de modelos exibindo metricas de avaliação\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, RocCurveDisplay\n",
    "arquivo = 'ML_supervised_learning'\n",
    "url = \"https://raw.githubusercontent.com/GabrielGabes/functions_gsa/main/\" + arquivo + \".py\"\n",
    "print(url); response = requests.get(url); code = response.text; exec(code)\n",
    "\n",
    "print('TUDO OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a6121",
   "metadata": {},
   "source": [
    "### Criando dataframe sintetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10335530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Gerar dados sintéticos desbalanceados\n",
    "x, y = make_classification(n_samples=7000, \n",
    "                           n_features=10, # qtd total de features\n",
    "                           n_informative=6, # features realmente uteis para o modelo\n",
    "                           n_redundant=3, # features que diz praticamente oque uma outra já fim\n",
    "                           n_classes=2, \n",
    "                           n_clusters_per_class=3,  # Subgrupos\n",
    "                           weights=[0.93, 0.07], \n",
    "                           class_sep=0.2, # separação entre as classes\n",
    "                           random_state=3141592)\n",
    "\n",
    "# Criar um DataFrame\n",
    "df = pd.DataFrame(x, columns=[f'feature_{i}' for i in range(x.shape[1])])\n",
    "df['target'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2204b6",
   "metadata": {},
   "source": [
    "### Tratando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5668ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5250, 10) (1750, 10)\n",
      "(5250,) (1750,)\n",
      "   count  proportion\n",
      "0   4865   92.666667\n",
      "1    385    7.333333\n",
      "   count  proportion\n",
      "0   1622   92.685714\n",
      "1    128    7.314286\n"
     ]
    }
   ],
   "source": [
    "# Variavel Dependente\n",
    "var_dep = 'target'\n",
    "y = df[var_dep]\n",
    "x = df.drop(var_dep, axis=1)\n",
    "\n",
    "############################################################################################\n",
    "# DUMMYRIZAÇÃO\n",
    "colunas_categoricas = []\n",
    "colunas_binarias = []\n",
    "colunas_mais3_categorias = []\n",
    "colunas_numericas = []\n",
    "\n",
    "for coluna in x.columns:\n",
    "    if df[coluna].dtype == 'O':\n",
    "        colunas_categoricas.append(coluna)\n",
    "\n",
    "        categorias = x[coluna].unique()\n",
    "        if len(categorias) == 2:\n",
    "            print('2 niveis:', coluna, '=>', categorias)\n",
    "            colunas_binarias.append(coluna)\n",
    "        else:\n",
    "            print('3 niveis:', coluna, '=>', categorias)\n",
    "            colunas_mais3_categorias.append(coluna)\n",
    "    else:\n",
    "        colunas_numericas.append(coluna)\n",
    "\n",
    "############################################################################################\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder #transformando colunas com 2 categorias em 0 e 1\n",
    "\n",
    "coluna = x.columns\n",
    "one_hot = make_column_transformer((\n",
    "    OneHotEncoder(drop='if_binary'), #caso a coluna tenha apenas 2 categorias \n",
    "    colunas_categoricas), #passando quais são essas colunas\n",
    "    remainder = 'passthrough', sparse_threshold=0) #oque deve ser feito com as outras\n",
    "\n",
    "#Aplicando transformação\n",
    "x = one_hot.fit_transform(x)\n",
    "\n",
    "#Os novos nomes das colunas #'onehotencoder=transformadas; 'remainder'=não transformadas\n",
    "novos_nomes_colunas = one_hot.get_feature_names_out(coluna)\n",
    "\n",
    "# Remover prefixo 'remainder__' das colunas que não foram transformadas\n",
    "#novos_nomes_colunas = [nome.replace('remainder__', '') for nome in novos_nomes_colunas]\n",
    "\n",
    "x = pd.DataFrame(x, columns = novos_nomes_colunas) #alterando de volta\n",
    "x_columns = x.columns.tolist() \n",
    "\n",
    "############################################################################################\n",
    "# Normalização (scaling entre 0 e 1) com MinMaxScaler ******************************\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizacao = MinMaxScaler()\n",
    "#x = normalizacao.fit_transform(x)\n",
    "# df['Close_normalizada'] = (df[coluna] - df[coluna].min()) / (df[coluna].max() - df[coluna].min())\n",
    "\n",
    "# Padronização (média 0 e desvio padrão 1) com StandardScaler **********************\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "padronizacao = StandardScaler()\n",
    "#x = padronizacao.fit_transform(x)\n",
    "# df['Close_padronizada'] = (df[coluna] - df[coluna].mean()) / df[coluna].std()\n",
    "\n",
    "############################################################################################\n",
    "# DEFININDO A VARIAVEL DEPENDENTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "############################################################################################\n",
    "#backups\n",
    "x_inteiro = x\n",
    "y_inteiro = y\n",
    "\n",
    "# DIVIDINDO BASE EM TREINO E TESTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, \n",
    "                                                    stratify = y, #para manter a proporção da Var Dep nos splits\n",
    "                                                    random_state = grandom_state) #raiz da aleatoridade\n",
    "# test_size = 0.25 #porcentagem que ira ser separado para testes\n",
    "\n",
    "print(x_treino.shape, x_teste.shape)\n",
    "\n",
    "print(y_treino.shape, y_teste.shape)\n",
    "print(pd.concat([pd.Series(y_treino).value_counts(), pd.Series(y_treino).value_counts(normalize=True)*100], axis=1))\n",
    "print(pd.concat([pd.Series(y_teste).value_counts(), pd.Series(y_teste).value_counts(normalize=True)*100], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316e778",
   "metadata": {},
   "source": [
    "# ======================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57387a3",
   "metadata": {},
   "source": [
    "# Aplicação basica do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297338d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7027c927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo os parâmetros do modelo. Neste caso, estamos utilizando o objetivo 'binary:logistic',\n",
    "# o que significa que o problema é de classificação binária, onde o modelo prevê probabilidades de uma classe binária.\n",
    "modelo_xgb = xgb.XGBClassifier(\n",
    "    objective='binary:logistic' \n",
    "    # Problema de classificação binária.\n",
    "    # é para que o modelo atribua valores de probabilidade para as classes\n",
    "    )\n",
    "modelo_xgb.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439b39b",
   "metadata": {},
   "source": [
    "O parâmetro `objective` no XGBoost define a função de perda (loss function) usada para treinar o modelo, ou seja, ele especifica o tipo de tarefa de aprendizado que você deseja resolver.\n",
    "\n",
    "No caso de `binary:logistic`, ele é utilizado para **classificação binária**. Esse objetivo pressupõe que o problema envolve duas classes e, portanto, treina o modelo para prever a probabilidade de uma instância pertencer à classe \"1\" (classe positiva), aplicando uma função logística (sigmoide) para transformar as saídas do modelo em probabilidades no intervalo [0, 1]. O resultado é a probabilidade associada à classe positiva.\n",
    "\n",
    "Quando você faz a predição com o modelo treinado, ele retorna um valor de probabilidade, e você pode definir um limiar para classificar as instâncias como pertencentes à classe 0 ou 1 (por exemplo, atribuir à classe 1 se a probabilidade for maior que 0,5).\n",
    "\n",
    "#### *Opções para o parâmetro `objective` no XGBoost*\n",
    "\n",
    "O parâmetro **`objective`** no XGBoost define a função de perda que será minimizada durante o treinamento, ou seja, a natureza do problema que o modelo está resolvendo (classificação binária, regressão, multiclass, etc.). Abaixo estão as principais opções para o parâmetro `objective`.\n",
    "\n",
    "*1. Objetivos para Classificação Binária:*\n",
    "- **`binary:logistic`**: Realiza classificação binária e gera probabilidades como saída (valores entre 0 e 1).\n",
    "- **`binary:hinge`**: Realiza classificação binária utilizando a perda de hinge, que é semelhante à usada no SVM. A saída será 0 ou 1 (em vez de probabilidades).\n",
    "\n",
    "*2. Objetivos para Classificação Multiclasse:*\n",
    "- **`multi:softmax`**: Realiza classificação multiclasse e retorna a classe prevista diretamente como saída (sem probabilidades). O número de classes é especificado com o parâmetro `num_class`.\n",
    "- **`multi:softprob`**: Realiza classificação multiclasse, mas retorna a distribuição de probabilidades para cada classe como saída. O número de classes também é especificado com o parâmetro `num_class`.\n",
    "\n",
    "*3. Objetivos para Regressão:*\n",
    "- **`reg:squarederror`**: Regressão utilizando o erro quadrático (Mean Squared Error, ou MSE). É a função de perda mais comum para regressão.\n",
    "- **`reg:squaredlogerror`**: Regressão utilizando o erro quadrático logarítmico (Squared Logarithmic Error). Útil quando os alvos variam em várias ordens de magnitude.\n",
    "- **`reg:logistic`**: Regressão logística. A saída é probabilística (valores entre 0 e 1).\n",
    "- **`reg:pseudohubererror`**: Usa a função de erro de Huber, que é robusta a outliers. Combina propriedades da MAE e MSE.\n",
    "\n",
    "*4. Objetivos para Rankeamento (Ranking):*\n",
    "- **`rank:pairwise`**: Utilizado para problemas de rankeamento. Classifica pares de exemplos com base na ordem relativa.\n",
    "- **`rank:ndcg`**: Maximiza a métrica Normalized Discounted Cumulative Gain (NDCG) para ranqueamento.\n",
    "- **`rank:map`**: Maximiza a métrica Mean Average Precision (MAP) para ranqueamento.\n",
    "\n",
    "*5. Outros Objetivos:*\n",
    "- **`count:poisson`**: Regressão para contagem de eventos, onde o alvo segue uma distribuição de Poisson.\n",
    "- **`survival:cox`**: Cox Proportional Hazards para modelagem de sobrevivência.\n",
    "- **`reg:gamma`**: Regressão com erro Gamma, útil para modelar variáveis positivas com alta assimetria.\n",
    "- **`reg:tweedie`**: Tweedie regression, apropriada para modelagem de distribuições compostas de Poisson e Gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e66234",
   "metadata": {},
   "source": [
    "## Avaliando modelo basico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f635c4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Matriz de Confusão:  :\n",
      "\n",
      "[[1611   11]\n",
      " [  94   34]]\n",
      "**************************************************\n",
      "Relatório de Classificação:  :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1622\n",
      "           1       0.76      0.27      0.39       128\n",
      "\n",
      "    accuracy                           0.94      1750\n",
      "   macro avg       0.85      0.63      0.68      1750\n",
      "weighted avg       0.93      0.94      0.93      1750\n",
      "\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "preds = modelo_xgb.predict(x_teste)\n",
    "avaliar_modelo(y_teste, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31520",
   "metadata": {},
   "source": [
    "# plotando grafico de uma das arvores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8289aa",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Configure o tamanho da figura e a resolução\n",
    "plt.figure(figsize=(15, 5), dpi=300)  # Ajuste o tamanho e a resolução conforme necessário\n",
    "\n",
    "Plotar a árvore\n",
    "xgb.plot_tree(modelo_xgb, \n",
    "              num_trees=1, # modelo N a ser visualizado\n",
    "              ax=plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921f99e",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf24b4",
   "metadata": {},
   "source": [
    "#### *Opções para o parâmetro `metrics` no XGBoost*\n",
    "\n",
    "O parâmetro **`metrics`** no XGBoost especifica a métrica usada para avaliar o desempenho do modelo durante o treinamento e validação. Existem várias opções de métricas, dependendo do tipo de problema que você está resolvendo (classificação binária, multiclasse, regressão, etc.). Abaixo estão as principais métricas disponíveis.\n",
    "\n",
    "*1. Métricas para Classificação Binária:*\n",
    "- **`error`**: Taxa de erro, que é a proporção de previsões incorretas.\n",
    "- **`logloss`**: Logarithmic Loss (ou Binary Cross-Entropy), que mede a incerteza das previsões, penalizando previsões incorretas com maior intensidade.\n",
    "- **`auc`**: Área sob a curva ROC, que mede a capacidade do modelo em classificar corretamente as classes.\n",
    "- **`aucpr`**: Área sob a curva Precision-Recall, útil quando as classes estão desbalanceadas.\n",
    "- **`map`**: Mean Average Precision, que mede a precisão média ponderada para problemas de classificação com múltiplos rótulos.\n",
    "\n",
    "*2. Métricas para Classificação Multiclasse:*\n",
    "- **`merror`**: Taxa de erro para classificação multiclasse.\n",
    "- **`mlogloss`**: Logarithmic Loss para problemas multiclasse.\n",
    "- **`auc`**: Área sob a curva ROC para o caso multiclasse, onde é calculada uma curva ROC para cada classe.\n",
    "\n",
    "*3. Métricas para Regressão:*\n",
    "- **`rmse`**: Root Mean Squared Error (Erro Quadrático Médio), que mede o erro médio entre as previsões e os valores reais.\n",
    "- **`mae`**: Mean Absolute Error (Erro Absoluto Médio), que mede o erro médio absoluto entre previsões e valores reais.\n",
    "- **`rmsle`**: Root Mean Squared Logarithmic Error, semelhante ao RMSE, mas calcula o erro sobre o logaritmo das previsões.\n",
    "- **`mape`**: Mean Absolute Percentage Error, que mede o erro médio percentual absoluto.\n",
    "- **`mphe`**: Mean Pseudo Huber Error, que é uma função de erro robusta que combina as propriedades da MAE e RMSE, sendo menos sensível a outliers.\n",
    "\n",
    "*4. Métricas para Rankeamento (Ranking):*\n",
    "- **`ndcg`**: Normalized Discounted Cumulative Gain, usada para avaliar a relevância em problemas de ranqueamento.\n",
    "- **`map`**: Mean Average Precision, usada também para ranqueamento.\n",
    "\n",
    "*5. Avaliação Customizada:*\n",
    "Você também pode definir suas próprias métricas personalizadas, passando uma função que receba as previsões e os valores reais e retorne um valor para a métrica customizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "083c3ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0          0.073286         0.001837         0.073285        0.003673\n",
      "1          0.067785         0.002250         0.069571        0.003581\n",
      "2          0.060500         0.001562         0.067428        0.002614\n",
      "3          0.057643         0.000796         0.065571        0.003194\n",
      "4          0.055286         0.000345         0.065142        0.003539\n",
      "Acuracia: 0.9447\n"
     ]
    }
   ],
   "source": [
    "# Criando um objeto DMatrix a partir dos dados de entrada (x) e dos rótulos (y).\n",
    "# DMatrix é uma estrutura de dados otimizada para trabalhar com o algoritmo XGBoost,\n",
    "# que facilita a manipulação eficiente de grandes quantidades de dados.\n",
    "dmatrix = xgb.DMatrix(data=x, label=y)\n",
    "\n",
    "# Definindo os parâmetros do modelo. Neste caso, estamos utilizando o objetivo 'binary:logistic',\n",
    "# o que significa que o problema é de classificação binária, onde o modelo prevê probabilidades de uma classe binária.\n",
    "params = {'objective': 'binary:logistic'}  # Problema de classificação binária.\n",
    "\n",
    "# Realizando a validação cruzada (cross-validation) com o XGBoost.\n",
    "cv_resultados = xgb.cv(dtrain=dmatrix,        # dtrain é o conjunto de treinamento que será passado como DMatrix.\n",
    "                       params=params,        # Os parâmetros definidos anteriormente (objetivo de classificação binária).\n",
    "                       nfold=3,              # O número de folds (partições) para a validação cruzada. Aqui são 3 folds.\n",
    "                       num_boost_round=5,    # Número de rounds de boosting. O modelo será treinado por 5 iterações. (numero de arvores)\n",
    "                       metrics='error',      # Métrica de desempenho. Aqui está sendo usada a 'error', que mede a taxa de erro (1 - acurácia).\n",
    "                       as_pandas=True,       # Definido como True para retornar os resultados em um DataFrame do Pandas.\n",
    "                       seed=123)             # Definindo uma semente aleatória para garantir a reprodutibilidade dos resultados.\n",
    "\n",
    "# Exibindo os resultados da validação cruzada.\n",
    "print(cv_resultados)\n",
    "acuracia = 1 - cv_resultados['train-error-mean'].iloc[-1]\n",
    "print('Acuracia:', acuracia.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e52f7f",
   "metadata": {},
   "source": [
    "Agora nosso objetivo será verificar se aumentar o número de rodadas de reforço faz com que o modelo melhore, e, consequentemente, a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc03ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic'}\n",
    "\n",
    "cv_resultados = xgb.cv(dtrain=dmatrix, params=params, nfold=3, \n",
    "                       num_boost_round=50, #**********\n",
    "                       metrics='error',\n",
    "                       as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_resultados) \n",
    "acuracia = 1 - cv_resultados['test-error-mean'].iloc[-1]\n",
    "print('Acuracia:', acuracia.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fea0a4",
   "metadata": {},
   "source": [
    "aumentar o número de rodadas não melhorou a acurácia. Vamos entender o motivo.\n",
    "\n",
    "Analisando o retorno gerado, notamos que muitas linhas estão com valor igual a 0. A partir da 14ª, porque a contagem começa em 0, já temos um desvio padrão igual a 0, e o valor do erro do nosso treino também está bem baixo, e depois fica 0 na rodada seguinte.\n",
    "\n",
    "Enfrentando um problema de overfitting\n",
    "Só temos 0 depois disso, ou seja, o modelo está decorando tudo para os dados de treino e acertando tudo, não estamos tendo erros, e isso é ruim. Não queremos que isso aconteça, porque isso é um sinal de overfitting.\n",
    "\n",
    "Se olharmos para os dados de teste, vamos verificar algo muito curioso. Até a 14ª rodada, temos um valor de erro de 0,20, depois esse erro aumenta para 0,21 na 16ª rodada, depois cai novamente para 0,20 e fica mais ou menos a mesma coisa.\n",
    "\n",
    "Então isso não está melhorando o nosso modelo, não foi algo positivo. Precisamos de uma quantidade de rodadas de reforço suficiente para que não ocorra overfitting e também que os nossos dados de teste tenham uma melhora e não fiquem estagnados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392c618",
   "metadata": {},
   "source": [
    "# Early Stopping\n",
    "Existe uma técnica que podemos usar com o XGBoost para saber qual é o número ideal de rodadas de reforço. Esta técnica se chama Early Stopping (Parada Antecipada).\n",
    "\n",
    "Podemos colocar qualquer valor de Boost Round, 100, 200, mas se definirmos o Early Stopping com um número mais baixo, ele vai parar quando for o momento certo. Ele vai perceber: \"O teste não está melhorando, então podemos parar agora\". Vamos aplicar essa técnica para entender como isso acontece.\n",
    "\n",
    "Vamos usar o mesmo código, copiá-lo e colá-lo na próxima célula, e agora vamos jogar um valor alto. Vamos colocar num_boost_round igual a 100, e adicionar o Early Stopping: early_stop_round = 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c14d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'binary:logistic'}\n",
    "\n",
    "cv_resultados = xgb.cv(dtrain=dmatrix, params=params, nfold=3, \n",
    "                       num_boost_round=100, #**********\n",
    "                       early_stopping_rounds= 5,\n",
    "                       metrics='error',\n",
    "                       as_pandas=True, seed=123)\n",
    "\n",
    "print(cv_resultados) \n",
    "acuracia = 1 - cv_resultados['test-error-mean'].iloc[-1]\n",
    "print('Acuracia:', acuracia.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fbed8",
   "metadata": {},
   "source": [
    "Quando definimos o número de early_stopping_rounds, ele costuma dar algumas rodadas a mais para conferir se o resultado está consistente, se realmente não há uma melhora. Se não tiver, ele vai parar, mas pode ir um pouquinho além do número que colocamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c7317",
   "metadata": {},
   "source": [
    "# *Hiperparâmetros do Modelo XGBoost*\n",
    "fonte: [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/parameter.html)\n",
    "\n",
    "O XGBoost (eXtreme Gradient Boosting) é um algoritmo avançado de aprendizado de máquina para problemas de regressão, classificação e ranking, conhecido por sua eficiência e desempenho. Os hiperparâmetros no XGBoost são essenciais para ajustar o modelo para obter a melhor performance possível. Aqui estão as principais categorias e hiperparâmetros utilizados no XGBoost:\n",
    "\n",
    "*1. Parâmetros Gerais*\n",
    "Estes parâmetros guiam a funcionalidade geral do XGBoost:\n",
    "- **`booster`**: Tipo de modelo a ser rodado. Opções incluem `gbtree`, `gblinear` ou `dart`. (Padrão: `gbtree`)\n",
    "- **`verbosity`**: Nível de verbosidade da saída impressa. Valores possíveis são 0 (silencioso), 1 (erro), 2 (informação) e 3 (depuração). (Padrão: 1)\n",
    "\n",
    "*2. Parâmetros de Booster*\n",
    "*Para `gbtree` e `dart`:*\n",
    "- **`eta`** (ou `learning_rate`): Taxa de aprendizado, usado para prevenir o sobreajuste. (Padrão: 0.3)\n",
    "    - Determina o quanto o modelo se ajusta à taxa de erro residual. Valores menores significam um aprendizado mais lento e mais robusto.\n",
    "    - Desempenha um papel crucial no ajuste do modelo ao erro residual com modelos base adicionais.\n",
    "    - O valor padrão é 0.3, mas pode ser ajustado entre 0 e 1.\n",
    "    - Taxas de aprendizado mais baixas requerem mais iterações para alcançar a mesma redução de erro, enquanto taxas mais altas podem acelerar o processo.\n",
    "\n",
    "- **`gamma`** (ou `min_split_loss`): Mínimo de redução de perda necessária para fazer uma divisão adicional em um nó da árvore. (Padrão: 0)\n",
    "    - Define a redução mínima de perdas necessária para realizar uma partição adicional em um nó da árvore.\n",
    "    - O padrão é 0, mas pode ser definido como qualquer inteiro positivo.\n",
    "    - Um valor mais alto torna o algoritmo mais conservador, resultando em menos divisões na árvore.\n",
    "\n",
    "- **`max_depth`**: Profundidade máxima de uma árvore. (Padrão: 6)\n",
    "    - Define a profundidade máxima da árvore. Aumentá-la pode tornar o modelo mais complexo e propenso ao overfitting.\n",
    "    - Afeta a profundidade máxima que cada árvore pode atingir em cada rodada de impulso.\n",
    "    - O valor padrão é 6, mas pode ser definido como qualquer inteiro positivo.\n",
    "    - Aumentar a profundidade pode levar a um modelo mais complexo e potencialmente a problemas de sobreajuste.\n",
    "\n",
    "- **`subsample`**: Fração de instâncias a serem amostradas para cada árvore. (Padrão: 1)\n",
    "    - Indica a fração do conjunto de treinamento utilizada em cada rodada de impulso.\n",
    "    - O padrão é 1, podendo ser ajustado entre 0 e 1.\n",
    "    - Valores baixos podem resultar em subajuste, enquanto valores altos podem levar a sobreajuste.\n",
    "\n",
    "- **`colsample_bytree`**, **`colsample_bylevel`**, **`colsample_bynode`**: Fração de colunas a serem amostradas para cada árvore, cada nível e cada divisão, respectivamente. (Padrão: 1 para todos)\n",
    "    - Determina a fração de features utilizada em cada rodada de impulso.\n",
    "    - O valor padrão é 1, indicando o uso de todas as features; pode ser ajustado entre 0 e 1.\n",
    "    - Valores menores fornecem regularização adicional, enquanto valores maiores podem levar a sobreajuste.\n",
    "\n",
    "*Para `gblinear`:*\n",
    "- **`lambda`**: Termo de regularização L2 no peso. (Padrão: 0)\n",
    "    - O parâmetro lambda é usado para controlar a penalização L2 (regularização Ridge) nas folhas da árvore.\n",
    "    - O valor padrão é 1, podendo ser ajustado para qualquer inteiro positivo.\n",
    "    - Ele adiciona uma penalidade à complexidade do modelo, ajudando a evitar o overfitting.\n",
    "    - Aumentar este valor torna o modelo mais conservador.\n",
    "- **`alpha`**: Termo de regularização L1 no peso. (Padrão: 0)\n",
    "    - O parâmetro alpha controla a penalização L1 (regularização Lasso) nas folhas da árvore.\n",
    "    - O padrão é 0, mas pode ser alterado para qualquer inteiro positivo.\n",
    "    - Assim como o parâmetro lambda, o alpha ajuda a controlar a complexidade do modelo e prevenir overfitting.\n",
    "    - Aumentar este valor aumenta a regularização e torna o modelo mais conservador.\n",
    "\n",
    "*Para `dart`:*\n",
    "- **`sample_type`**: Tipo de amostragem de árvores. (Padrão: `uniform`)\n",
    "- **`normalize_type`**: Tipo de normalização. (Padrão: `tree`)\n",
    "- **`rate_drop`**: Fração de árvores a serem descartadas durante a fase de dropout. (Padrão: 0)\n",
    "\n",
    "*3. Parâmetros de Aprendizado*\n",
    "- **`objective`**: Define a função objetivo, como `binary:logistic`, `multi:softmax`, `reg:squarederror`, etc.\n",
    "- **`base_score`**: A previsão inicial de todas as instâncias, global. (Padrão: 0.5)\n",
    "- **`eval_metric`**: Métrica de avaliação para validação cruzada.\n",
    "- **`seed`**: Semente para a geração de números aleatórios. (Padrão: 0)\n",
    "\n",
    "*4. Parâmetros de Controle de Tarefas*\n",
    "- **`nthread`** (ou `n_jobs`): Número de threads paralelas usadas para rodar o XGBoost. (Padrão: número máximo de threads disponíveis)\n",
    "- **`num_parallel_tree`**: Número de árvores a serem construídas em paralelo. (Padrão: 1)\n",
    "- **`predictor`**: Tipo de preditor a ser usado, `auto`, `cpu_predictor` ou `gpu_predictor`. (Padrão: `auto`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae249f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'binary:logistic', \n",
    "          'colsample_bytree': 0.3,\n",
    "          'learning_rate': 0.1, \n",
    "          'max_depth': 5\n",
    "          }\n",
    "                    \n",
    "cv_resultados = xgb.cv(dtrain=dmatrix, \n",
    "                       params=params,\n",
    "                       nfold=3, \n",
    "                       num_boost_round=100,\n",
    "                       early_stopping_rounds= 5,\n",
    "                       metrics='error', \n",
    "                       as_pandas=True, \n",
    "                       seed=123)\n",
    "\n",
    "print(cv_resultados)\n",
    "acuracia = 1 - cv_resultados['test-error-mean'].iloc[-1]\n",
    "print(f'Acuracia: {acuracia}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd99ce",
   "metadata": {},
   "source": [
    "# Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f68156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'max_depth': [0, 2, 4, 6, 10], \n",
    "        'colsample_bytree': [0.1, 0.5, 1],\n",
    "        'n_estimators': [3, 5, 7, 10, 15, 25, 50, 100],\n",
    "}\n",
    "\n",
    "modelo_xgb = xgb.XGBClassifier()\n",
    "random_search_cv = RandomizedSearchCV(estimator=modelo_xgb, \n",
    "                                      param_distributions=params, \n",
    "                                      n_iter=50, \n",
    "                                      cv=4, \n",
    "                                      scoring='accuracy', \n",
    "                                      verbose=1,\n",
    "                                      random_state=3141592)\n",
    "random_search_cv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baaf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhores parametros encontrados: ', random_search_cv.best_params_)\n",
    "print(\"Acuracia:\", random_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f82412",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(random_search_cv.cv_results_)\n",
    "pos_teste_numcat(cv_results, 'param_max_depth', 'mean_test_score')\n",
    "grafico_numcat(cv_results, 'param_max_depth', 'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a7ff1",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "        'learning_rate': [0.1, 0.2, 0.3],\n",
    "        'max_depth': [0, 2, 4, 6, 8, 10], \n",
    "        'colsample_bytree': [0.1, 0.5, 1],\n",
    "        'n_estimators': [3, 5, 10, 25, 50, 100],\n",
    "}\n",
    "\n",
    "modelo_xgb = xgb.XGBClassifier()\n",
    "grid_search_cv = GridSearchCV(estimator=modelo_xgb, \n",
    "                              param_grid=params, \n",
    "                              cv=4, \n",
    "                              scoring='accuracy', \n",
    "                              verbose=1)\n",
    "grid_search_cv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce65b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Melhores parametros encontrados: ', grid_search_cv.best_params_)\n",
    "print('Melhores parametros encontrados no random: ', random_search_cv.best_params_)\n",
    "print(\"Acuracia:\", grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "pos_teste_numcat(cv_results, 'param_max_depth', 'mean_test_score')\n",
    "grafico_numcat(cv_results, 'param_max_depth', 'mean_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad104c7",
   "metadata": {},
   "source": [
    "# Modelo ajustado com os melhores parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl_ajustado = xgb.XGBClassifier(objective='binary:logistic', \n",
    "                                   colsample_bytree = 0.5, \n",
    "                                   learning_rate = 0.1, \n",
    "                                   max_depth = 10, \n",
    "                                   n_estimators = 100)\n",
    "xg_cl_ajustado.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a0bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_cl_ajustado.predict(x_teste)\n",
    "avaliar_modelo(preds, y_teste, plotar_grafico=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8225de",
   "metadata": {},
   "source": [
    "# Incorporando XGBoost em pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b3452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    #('oversample', SMOTE()),\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'xgb__learning_rate': [0.1, 0.2, 0.3],\n",
    "    'xgb__max_depth': [1, 2, 4, 6, 10],\n",
    "    'xgb__colsample_bytree': [0.1, 0.5, 1],\n",
    "    'xgb__n_estimators': [10, 25, 50]\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV(estimator=pipeline, param_grid=xgb_param_grid,\n",
    "                              scoring='accuracy', cv=4, verbose=1)\n",
    "\n",
    "grid_search_cv.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f557969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Acuracia:', grid_search_cv.best_score_)\n",
    "print('Melhor estimador:', grid_search_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a433f6b",
   "metadata": {},
   "source": [
    "# Salvando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(grid_search_cv, 'modelo_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = modelo.predict(novos_pacientes)\n",
    "probabilidades = modelo.predict_proba(novos_pacientes)\n",
    "\n",
    "df_novos_pacientes = pd.DataFrame(novos_pacientes)\n",
    "df_novos_pacientes['previsoes'] = previsoes\n",
    "\n",
    "df_novos_pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4deed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da2041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2adafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914d339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d068f2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729c81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b96ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca05094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a0b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4cd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b540c7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
