{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493c9aa0",
   "metadata": {},
   "source": [
    "# Book 2 - Selecionamento de Features, Validação, Balanceamento\n",
    "\n",
    "Este notebook serviu como registro prático e teórico no meu aprendizado de Machine Learning.\n",
    "\n",
    "`Enriqueci este notebook com anotações adicionais e aplicações práticas tornando-o uma referência valiosa para consultas e implementações em futuros projetos reais.`\n",
    "\n",
    "Espero que este material inspire outros a explorar ainda mais o fascinante mundo do Machine Learning. \n",
    "\n",
    "No notebook presente tem todos os topicos dos notebook anteriores, porém sendo acrescentado e aprofundado com anotações dos seguintes tópicos:\n",
    "\n",
    "**Técnicas de Balanceamento de Dados**  \n",
    "- **Oversampling - Upsampling**: Criação de dados sintéticos.\n",
    "- **Undersampling - Downsampling**: Redução de amostras na classe majoritária.\n",
    "\n",
    "Compartilhar conhecimento é uma alegria—viva ao aprendizado contínuo, boa pratica e bons estudo a quem estiver lendo, abraços!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f8891",
   "metadata": {},
   "source": [
    "# Funções, bibliotecas e Dataframe ficticios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871c9bd8-f30f-47bc-9b65-b7c6a304e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "\n",
    "# Manipulação e Tratamento de dados\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import NaN\n",
    "\n",
    "#ignorando Warning inuteis\n",
    "import warnings \n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e337084-09eb-4f3f-9ba7-e68890a0a6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar os dados\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Identificar colunas a serem removidas # Remover colunas inúteis\n",
    "columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3891df6-0b02-4b57-8056-b3fc5e5b0d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 712 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  712 non-null    int64  \n",
      " 1   Pclass    712 non-null    int64  \n",
      " 2   Sex       712 non-null    object \n",
      " 3   Age       712 non-null    float64\n",
      " 4   SibSp     712 non-null    int64  \n",
      " 5   Parch     712 non-null    int64  \n",
      " 6   Fare      712 non-null    float64\n",
      " 7   Embarked  712 non-null    object \n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 50.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f208bb-c183-4573-be25-fd571b99a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_cat = ['Pclass','Sex','Embarked']\n",
    "for coluna in colunas_cat:\n",
    "    df[coluna] = df[coluna].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2977547-74b2-48bb-a3ab-cdfb6a1d2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Survived', axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14649559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 niveis: Pclass => [3 1 2]\n",
      "2 niveis: Sex => ['male' 'female']\n",
      "3 niveis: Embarked => ['S' 'C' 'Q']\n",
      "(534, 11) (178, 11)\n",
      "(534,) (178,)\n"
     ]
    }
   ],
   "source": [
    "# DUMMYRIZAÇÃO\n",
    "colunas_categoricas = []\n",
    "colunas_binarias = []\n",
    "colunas_mais3_categorias = []\n",
    "\n",
    "for coluna in x.columns:\n",
    "    if df[coluna].dtype == 'O':\n",
    "        categorias = x[coluna].unique()\n",
    "        if len(categorias) == 2:\n",
    "            print('2 niveis:', coluna, '=>', categorias)\n",
    "            colunas_categoricas.append(coluna)\n",
    "            colunas_binarias.append(coluna)\n",
    "        else:\n",
    "            print('3 niveis:', coluna, '=>', categorias)\n",
    "            colunas_categoricas.append(coluna)\n",
    "            colunas_mais3_categorias.append(coluna)\n",
    "\n",
    "############################################################################################\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder #transformando colunas com 2 categorias em 0 e 1\n",
    "\n",
    "coluna = x.columns\n",
    "one_hot = make_column_transformer((\n",
    "    OneHotEncoder(drop='if_binary'), #caso a coluna tenha apenas 2 categorias \n",
    "    colunas_categoricas), #passando quais são essas colunas\n",
    "    remainder = 'passthrough', sparse_threshold=0) #oque deve ser feito com as outras\n",
    "\n",
    "#Aplicando transformação\n",
    "x = one_hot.fit_transform(x)\n",
    "\n",
    "#Os novos nomes das colunas #'onehotencoder=transformadas; 'remainder'=não transformadas\n",
    "novos_nomes_colunas = one_hot.get_feature_names_out(coluna)\n",
    "\n",
    "# Remover prefixo 'remainder__' das colunas que não foram transformadas\n",
    "#novos_nomes_colunas = [nome.replace('remainder__', '') for nome in novos_nomes_colunas]\n",
    "\n",
    "x = pd.DataFrame(x, columns = novos_nomes_colunas) #alterando de volta\n",
    "x_columns = x.columns.tolist() \n",
    "\n",
    "############################################################################################\n",
    "# Normalização (scaling entre 0 e 1) com MinMaxScaler ******************************\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizacao = MinMaxScaler()\n",
    "#x = normalizacao.fit_transform(x)\n",
    "# df['Close_normalizada'] = (df[coluna] - df[coluna].min()) / (df[coluna].max() - df[coluna].min())\n",
    "\n",
    "# Padronização (média 0 e desvio padrão 1) com StandardScaler **********************\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "padronizacao = StandardScaler()\n",
    "#x = padronizacao.fit_transform(x)\n",
    "# df['Close_padronizada'] = (df[coluna] - df[coluna].mean()) / df[coluna].std()\n",
    "\n",
    "############################################################################################\n",
    "# DEFININDO A VARIAVEL DEPENDENTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "############################################################################################\n",
    "#backups\n",
    "x_inteiro = x\n",
    "y_inteiro = y\n",
    "\n",
    "# DIVIDINDO BASE EM TREINO E TESTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_treino, x_teste, y_treino, y_teste = train_test_split(x, y, \n",
    "                                                    stratify = y, #para manter a proporção da Var Dep nos splits\n",
    "                                                    random_state = 5) #raiz da aleatoridade\n",
    "# test_size = 0.25 #porcentagem que ira ser separado para testes\n",
    "\n",
    "print(x_treino.shape, x_teste.shape)\n",
    "print(y_treino.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95981770",
   "metadata": {},
   "source": [
    "# ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33f938",
   "metadata": {},
   "source": [
    "# Balanceamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c43ba",
   "metadata": {},
   "source": [
    "# ===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de32341-8575-4a68-803d-71a386557dd1",
   "metadata": {},
   "source": [
    "# Oversampling - Upsampling\n",
    "\n",
    "Abordagem avançada de oversampling usada para balancear conjuntos de dados desbalanceados, aumentando a representatividade das classes minoritárias por meio da `criação de dados sintéticos`, ao invés de simplesmente replicar os exemplos existentes.\n",
    "\n",
    "(Exemplo SMOTE)\n",
    "\n",
    "- **Diversificação:** Ao gerar novos exemplos, SMOTE introduz uma variedade maior no conjunto de dados, o que pode ajudar a evitar o overfitting que poderia ocorrer se simplesmente duplicássemos as amostras existentes.\n",
    "- **Melhoria de Modelagem:** Com um balanceamento mais efetivo entre as classes, os modelos são capazes de aprender padrões mais generalizáveis, melhorando assim a precisão das previsões em dados não vistos.\n",
    "\n",
    "SMOTE é amplamente utilizado em problemas de classificação onde o desequilíbrio de classes é significativo, como em detecção de fraude, diagnóstico médico e predição de falhas em equipamentos.\n",
    "\n",
    "**Funcionamento**\n",
    "\n",
    "1. **Identificação das Amostras:**\n",
    "   SMOTE analisa as características das amostras minoritárias (classe sub-representada) e identifica seus vizinhos mais próximos.\n",
    "\n",
    "2. **Síntese de Novos Exemplos:**\n",
    "   Para cada amostra na classe minoritária, são criados novos exemplos sintéticos. Isso é feito selecionando um dos \\( k \\) vizinhos mais próximos (geralmente \\( k=5 \\)) e interpolando um novo ponto entre a amostra original e o vizinho selecionado.\n",
    "\n",
    "3. **Adição ao Conjunto de Dados:**\n",
    "   Os exemplos sintéticos gerados são então adicionados ao conjunto de dados, aumentando a proporção da classe minoritária.\n",
    "\n",
    "**Considerações**\n",
    "\n",
    "- **Espaço de Características:** SMOTE funciona bem quando as características são contínuas. Em dados categóricos, outras técnicas de oversampling, como o ADASYN (Adaptive Synthetic Sampling Approach), podem ser mais apropriadas.\n",
    "- **Risco de Overfitting:** Apesar de introduzir diversidade, a criação de muitos exemplos sintéticos pode levar a um modelo excessivamente otimista em relação aos dados de treinamento. Deve-se ter cautela com o número de exemplos sintéticos gerados.\n",
    "- **Não Adiciona Novas Informações:** Como as amostras são apenas replicadas, nenhuma informação nova é introduzida ao modelo, o que pode limitar a capacidade do modelo de aprender nuances mais complexas das classes.\n",
    "- **Combinação com Downsampling:** Frequentemente, o upsampling é combinado com o downsampling da classe majoritária para criar um equilíbrio ainda mais efetivo e evitar o aumento excessivo do conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separando por classe\n",
    "x_inteiro_df = pd.DataFrame(x_inteiro)\n",
    "y_inteiro_series = pd.Series(y_inteiro)\n",
    "classe_maior = x_inteiro_df.iloc[sorted(y_inteiro_series[y_inteiro_series == 1].index)]\n",
    "classe_menor = x_inteiro_df.iloc[sorted(y_inteiro_series[y_inteiro_series == 0].index)]\n",
    "\n",
    "# Upsampling da classe minoritária\n",
    "train_df_menor_upsampled = resample(classe_menor,\n",
    "                                    replace=True,                # sample with replacement\n",
    "                                    n_samples=len(classe_menor), # to match majority class\n",
    "                                    random_state=123)            # reproducible results\n",
    "\n",
    "# Combinando a classe majoritária com a classe minoritária upsampled\n",
    "train_df_upsampled = pd.concat([classe_menor, train_df_menor_upsampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5065d5",
   "metadata": {},
   "source": [
    "## SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "Gera novos exemplos sintéticos da classe minoritária ao invés de duplicar exemplos existentes. Funciona interpolando entre os exemplos minoritários e criando novos pontos ao longo das linhas que ligam os vizinhos mais próximos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "x_treino_balanceado, y_treino_balanceado = smote.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17534f67",
   "metadata": {},
   "source": [
    "## Variantes do SMOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a88192",
   "metadata": {},
   "source": [
    "### Borderline-SMOTE\n",
    "Aplica oversampling apenas nos exemplos da classe minoritária que estão perto da fronteira com a classe majoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee24b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borderline-SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "borderline_smote = BorderlineSMOTE()\n",
    "x_treino_balanceado, y_treino_balanceado = borderline_smote.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84dfc61",
   "metadata": {},
   "source": [
    "### SMOTE-ENN (Edited Nearest Neighbours)\n",
    "Combina SMOTE com um método de limpeza dos dados chamado ENN, que remove exemplos ruidosos após o oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE-ENN\n",
    "from imblearn.combine import SMOTEENN\n",
    "smote_enn = SMOTEENN()\n",
    "x_treino_balanceado, y_treino_balanceado = smote_enn.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bc22d",
   "metadata": {},
   "source": [
    "### ADASYN (Adaptive Synthetic Sampling)\n",
    "Variante do SMOTE que ajusta o número de exemplos sintéticos gerados com base na densidade local, gerando mais exemplos para minorias que estão cercadas por muitas instâncias da classe majoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN\n",
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN()\n",
    "x_treino_balanceado, y_treino_balanceado = adasyn.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7dc309",
   "metadata": {},
   "source": [
    "### K-means SMOTE\n",
    "Uma variante do SMOTE que usa agrupamento (k-means clustering) antes de aplicar o SMOTE, gerando exemplos sintéticos baseados nos clusters de dados minoritários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5789d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means SMOTE\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "kmeans_smote = KMeansSMOTE()\n",
    "x_treino_balanceado, y_treino_balanceado = kmeans_smote.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed1b11",
   "metadata": {},
   "source": [
    "### Random Oversampling\n",
    "Duplica aleatoriamente exemplos da classe minoritária até atingir um balanço desejado. Isso pode levar à overfitting, já que os mesmos exemplos são repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896961b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = oversampler.fit_resample(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693deb3-2367-446c-8758-fa1e10921db1",
   "metadata": {},
   "source": [
    "# Undersampling - Downsampling\n",
    "\n",
    "Em resumo: Reduzem o número de exemplos da classe majoritária, removendo instâncias de forma controlada para equilibrar o conjunto.\n",
    "\n",
    "Este método específico foca na `redução da classe majoritária`, mas com uma abordagem mais refinada que simplesmente remover amostras aleatoriamente. O NearMiss seleciona amostras da classe majoritária baseado em certos critérios de proximidade, com o objetivo de manter apenas aquelas que são mais representativas e/ou mais próximas das amostras da classe minoritária.\n",
    "\n",
    "**Funcionamento (NearMiss)**\n",
    "\n",
    "1. **Critérios de Seleção:**\n",
    "   NearMiss implementa diferentes versões de seleção:\n",
    "   - **NearMiss-1:** Seleciona amostras da classe majoritária com a menor distância média às três amostras mais próximas da classe minoritária.\n",
    "   - **NearMiss-2:** Seleciona amostras da classe majoritária com a menor distância média às três amostras mais distantes da classe minoritária.\n",
    "   - **NearMiss-3:** Um subconjunto da classe minoritária é selecionado primeiro, e então, para cada exemplo na classe minoritária, são retidas as \\( n \\) amostras mais próximas da classe majoritária.\n",
    "\n",
    "2. **Redução da Classe Majoritária:**\n",
    "   Amostras são selecionadas de acordo com o critério estabelecido até que o número de instâncias na classe majoritária seja reduzido suficientemente para igualar o da classe minoritária.\n",
    "\n",
    "3. **Combinação de Dados:**\n",
    "   As amostras da classe majoritária que atendem aos critérios são combinadas com as da classe minoritária para formar um novo conjunto de dados balanceado.\n",
    "\n",
    "**Considerações**\n",
    "\n",
    "- **Perda de Informação Crítica:** Apesar da intenção de manter amostras importantes, a remoção de grandes quantidades de dados pode resultar em perda de informações cruciais.\n",
    "- **Escolha do Método:** A escolha entre NearMiss-1, NearMiss-2, e NearMiss-3 pode ter um impacto significativo nos resultados, exigindo testes para determinar qual método se adapta melhor ao problema específico.\n",
    "- **Escolha de Amostras:** A seleção aleatória de amostras para remoção pode não ser a abordagem ideal; métodos mais sofisticados podem ser necessários para preservar a integridade da informação.\n",
    "- **Combinação com Upsampling:** Muitas vezes, o downsampling é usado em conjunto com o upsampling para não apenas reduzir a classe majoritária, mas também aumentar a minoritária, alcançando um equilíbrio ideal.\n",
    "- **Técnicas Avançadas:** Métodos como clustering ou análises de importância de instâncias podem ser utilizados para escolher quais amostras remover, assegurando que as mais representativas e informativas sejam mantidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cec2c2",
   "metadata": {},
   "source": [
    "## Random Undersampling\n",
    "Remove exemplos da classe majoritária aleatoriamente. Embora simples, pode resultar na perda de informações importantes se não for usado com cuidado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52472b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "x_treino_balanceado, y_treino_balanceado = rus.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644381de",
   "metadata": {},
   "source": [
    "## NearMiss\n",
    "Seleciona exemplos da classe majoritária que estão mais próximos dos exemplos da classe minoritária, tentando manter exemplos representativos da classe majoritária.\n",
    "\n",
    "> NearMiss-1: \n",
    "    Escolhe exemplos da classe majoritária com a menor distância média para os três exemplos mais próximos da classe minoritária.\n",
    "\n",
    "    \n",
    "> NearMiss-2:\n",
    "    Escolhe exemplos da classe majoritária com a menor distância média para todos os exemplos da classe minoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NearMiss\n",
    "from imblearn.under_sampling import NearMiss\n",
    "near_miss = NearMiss(version=3)\n",
    "x_treino_balanceado, y_treino_balanceado = near_miss.fit_resample(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6ef9e",
   "metadata": {},
   "source": [
    "## Tomek Links\n",
    "Identifica pares de exemplos (um da classe majoritária e um da minoritária) que são vizinhos mais próximos e pertencem a classes diferentes. Se esses pares forem encontrados, o exemplo da classe majoritária é removido, limpando a fronteira entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe465a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomek Links\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "tomek_links = TomekLinks()\n",
    "x_treino_balanceado, y_treino_balanceado = tomek_links.fit_resample(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a738f8a",
   "metadata": {},
   "source": [
    "## Cluster Centroids\n",
    "Uma técnica de undersampling baseada em clusterização, onde os dados da classe majoritária são agrupados e os centróides desses clusters substituem os exemplos originais. Isso reduz o número de exemplos da classe majoritária sem perder muita representatividade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca4789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Centroids\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cluster_centroids = ClusterCentroids()\n",
    "x_treino_balanceado, y_treino_balanceado = cluster_centroids.fit_resample(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c4789",
   "metadata": {},
   "source": [
    "# Técnicas Combinadas (Over/Under Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c7c13",
   "metadata": {},
   "source": [
    "## SMOTE + Tomek Links\n",
    "Primeiro aplica SMOTE para gerar exemplos sintéticos da classe minoritária e depois aplica Tomek Links para remover exemplos da classe majoritária que estão muito próximos da classe minoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE + Tomek Links\n",
    "from imblearn.combine import SMOTETomek\n",
    "smote_tomek = SMOTETomek()\n",
    "x_treino_balanceado, y_treino_balanceado = smote_tomek.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de38e63",
   "metadata": {},
   "source": [
    "## SMOTE + NearMiss\n",
    "Combina SMOTE para a classe minoritária com NearMiss para a classe majoritária, criando um equilíbrio mais controlado entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc662e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE + NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Aplicando SMOTE para oversampling\n",
    "smote = SMOTE()\n",
    "x_treino_oversampled, y_treino_oversampled = smote.fit_resample(x_treino, y_treino)\n",
    "\n",
    "# Aplicando NearMiss para undersampling\n",
    "near_miss = NearMiss(version=3)\n",
    "x_treino_balanceado, y_treino_balanceado = near_miss.fit_resample(x_treino_oversampled, y_treino_oversampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780d3b0",
   "metadata": {},
   "source": [
    "# Técnicas Baseadas em Algoritmos\n",
    "Alguns algoritmos de machine learning possuem abordagens internas para lidar com dados desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ccd46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b28705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Aplicando pesos de classe para balanceamento automático\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84037eae",
   "metadata": {},
   "source": [
    "## BalancedRandomForest\n",
    "Uma técnica baseada em árvores de decisão que cria várias árvores com conjuntos de dados balanceados. Em cada árvore, realiza undersampling da classe majoritária de forma aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Random Forest\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier()\n",
    "brf.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd5ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Bagging Classifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "bbc.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff1db9",
   "metadata": {},
   "source": [
    "# Técnicas de Amostragem Informatizada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a13653",
   "metadata": {},
   "source": [
    "## Edited Nearest Neighbors (ENN)\n",
    "Remove exemplos da classe majoritária e da minoritária que são mal classificados pelos seus vizinhos mais próximos, ajudando a melhorar a separação entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edited Nearest Neighbors (ENN)\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "enn = EditedNearestNeighbours()\n",
    "x_treino_balanceado, y_treino_balanceado = enn.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fe3ff",
   "metadata": {},
   "source": [
    "## Repeated Edited Nearest Neighbors (RENN)\n",
    "Aplica o processo de ENN repetidamente até que nenhum exemplo seja removido, limpando ainda mais as fronteiras entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated Edited Nearest Neighbours (RENN)\n",
    "from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "x_treino_balanceado, y_treino_balanceado = renn.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36248d4a",
   "metadata": {},
   "source": [
    "## One-Sided Selection (OSS)\n",
    "Combina Tomek Links com ENN para limpar a classe majoritária, removendo exemplos ruidosos e fronteiriços."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Sided Selection (OSS)\n",
    "from imblearn.under_sampling import OneSidedSelection\n",
    "oss = OneSidedSelection()\n",
    "x_treino_balanceado, y_treino_balanceado = oss.fit_resample(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef452a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ee29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715ab01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f59a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413e1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7002af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c013e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f268752d",
   "metadata": {},
   "source": [
    "# FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761d81d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fa190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd431387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef6c72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
